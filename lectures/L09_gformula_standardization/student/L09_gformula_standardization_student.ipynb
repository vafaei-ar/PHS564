{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b20a414",
   "metadata": {},
   "source": [
    "# PHS564 — Lecture 09 (Student)\n",
    "## Standardization + (parametric) g-formula (and “why model”) (MIMIC-IV Demo)\n",
    "\n",
    "### Learning goals\n",
    "- Derive and implement standardization:\n",
    "- \\(Pr(Y^a=1)=\\sum_l Pr(Y=1|A=a,L=l)\\,Pr(L=l)\\) (discrete \\(L\\))\n",
    "- parametric g-formula for high-dimensional \\(L\\)\n",
    "- Connect **estimand → identification → estimator → computation** (this is the “why model” message).\n",
    "- Compare g-formula vs IPW and articulate tradeoffs (model dependence vs weight instability).\n",
    "- Bootstrap the full procedure for uncertainty.\n",
    "\n",
    "### Required reading\n",
    "- Hernán & Robins, g-formula/standardization sections (aligned chapter in *What If*).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3a338f",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "This notebook is designed to run **locally** or in **Google Colab**.\n",
    "\n",
    "**Colab workflow (recommended):**\n",
    "1) Clone the course repo (ask the instructor for the GitHub URL).\n",
    "2) Install requirements.\n",
    "3) Run the notebook top-to-bottom.\n",
    "\n",
    "> If you opened this notebook directly from GitHub in Colab (without cloning),\n",
    "> relative paths will not work. Clone first.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b165ef50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reproducibility\n",
    "RNG = np.random.default_rng(564)\n",
    "\n",
    "# Locate repo root (works when running from lectures/Lxx.../student or /instructor)\n",
    "THIS_DIR = Path.cwd()\n",
    "REPO_ROOT = THIS_DIR\n",
    "for _ in range(4):\n",
    "    if (REPO_ROOT / \"requirements.txt\").exists() or (REPO_ROOT / \"README.md\").exists():\n",
    "        break\n",
    "    REPO_ROOT = REPO_ROOT.parent\n",
    "\n",
    "DATA_DIR = REPO_ROOT / \"data\"\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "PROC_DIR = DATA_DIR / \"processed\"\n",
    "\n",
    "print(\"Working directory:\", THIS_DIR)\n",
    "print(\"Repo root:\", REPO_ROOT)\n",
    "print(\"Processed data dir exists:\", PROC_DIR.exists())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c12ca66",
   "metadata": {},
   "source": [
    "### Download MIMIC-IV Demo data (if needed)\n",
    "\n",
    "**Important for Google Colab users:** If you are running this notebook in Google Colab, you should run the cell below to download the raw MIMIC-IV Demo data. This is needed if you want to explore the raw data or if the instructor asks you to work with it.\n",
    "\n",
    "**Local users:** You can skip this cell if you already have the data, or run it if you need to download it.\n",
    "\n",
    "> **Note:** This downloads the raw MIMIC-IV Demo data to `data/raw/`. The notebook will use a pre-processed cohort extract from `data/processed/`, but having the raw data available can be useful for exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc68ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download MIMIC-IV Demo data (Colab-friendly)\n",
    "# This cell can be skipped if you already have the data or are running locally\n",
    "\n",
    "# Add repo root to path to import download function\n",
    "if str(REPO_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(REPO_ROOT))\n",
    "\n",
    "try:\n",
    "    from data.download_data import download_mimic_demo\n",
    "    \n",
    "    # Check if data already exists\n",
    "    mimic_dir = RAW_DIR / \"mimic-iv-demo-2.2\"\n",
    "    if mimic_dir.exists() and any(mimic_dir.rglob(\"*.csv.gz\")):\n",
    "        print(\"✓ MIMIC-IV Demo data already exists. Skipping download.\")\n",
    "    else:\n",
    "        print(\"Downloading MIMIC-IV Demo data...\")\n",
    "        print(\"(This may take a few minutes. The data is ~7 MB compressed.)\")\n",
    "        download_mimic_demo(out_dir=str(RAW_DIR), method=\"python\")\n",
    "except Exception as e:\n",
    "    print(f\"Note: Could not download data: {e}\")\n",
    "    print(\"You can skip this cell if you already have the processed cohort extract.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf435b3f",
   "metadata": {},
   "source": [
    "## Data\n",
    "Expected file: `data/processed/cohort_L09_gformula.parquet` (or `.csv`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7e3e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statsmodels for regression (logit/ols); installed via requirements.txt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "parquet_path = PROC_DIR / \"cohort_L09_gformula.parquet\"\n",
    "csv_path = PROC_DIR / \"cohort_L09_gformula.csv\"\n",
    "\n",
    "if parquet_path.exists():\n",
    "    df = pd.read_parquet(parquet_path)\n",
    "elif csv_path.exists():\n",
    "    df = pd.read_csv(csv_path)\n",
    "else:\n",
    "    raise FileNotFoundError(\"Missing cohort file for L09. Run `python data/download_data.py`.\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41a5b8e",
   "metadata": {},
   "source": [
    "### Choose variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af20c5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = \"A\"   # TODO\n",
    "Y = \"Y\"   # TODO\n",
    "L_list = [\"age\", \"sex\"]  # TODO\n",
    "\n",
    "analysis_vars = [A, Y] + L_list\n",
    "d = df[analysis_vars].dropna().copy()\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67e79c8",
   "metadata": {},
   "source": [
    "## Part A — Outcome regression model\n",
    "Students only specify the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42189947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: specify model for E[Y | A, L]\n",
    "# If Y is binary, use logit; if continuous, use OLS.\n",
    "# Start with: \"Y ~ A + age + sex\"\n",
    "outcome_formula = Y + \" ~ \" + \" + \".join([A] + L_list)\n",
    "\n",
    "# Choose model type (auto-guess binary if only 0/1 values)\n",
    "is_binary = set(d[Y].dropna().unique()).issubset({0,1})\n",
    "\n",
    "if is_binary:\n",
    "    y_model = smf.logit(outcome_formula, data=d).fit(disp=False)\n",
    "else:\n",
    "    y_model = smf.ols(outcome_formula, data=d).fit()\n",
    "\n",
    "y_model.summary().tables[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de03845",
   "metadata": {},
   "source": [
    "## Part B — Standardization (parametric g-formula)\n",
    "Predict outcomes under A=1 and A=0 for everyone, then average.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a73e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = d.copy(); d1[A] = 1\n",
    "d0 = d.copy(); d0[A] = 0\n",
    "\n",
    "pred1 = y_model.predict(d1)\n",
    "pred0 = y_model.predict(d0)\n",
    "\n",
    "mu1 = float(np.mean(pred1))\n",
    "mu0 = float(np.mean(pred0))\n",
    "ate = mu1 - mu0\n",
    "{\"mu1\": mu1, \"mu0\": mu0, \"ATE\": ate}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062e50f2",
   "metadata": {},
   "source": [
    "### TODO B1 — Bootstrap CI for ATE (optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da204e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gformula_ate(data: pd.DataFrame) -> float:\n",
    "    # Fit model and compute ATE (same specification as above)\n",
    "    is_binary = set(data[Y].dropna().unique()).issubset({0,1})\n",
    "    if is_binary:\n",
    "        m = smf.logit(outcome_formula, data=data).fit(disp=False)\n",
    "    else:\n",
    "        m = smf.ols(outcome_formula, data=data).fit()\n",
    "    d1 = data.copy(); d1[A]=1\n",
    "    d0 = data.copy(); d0[A]=0\n",
    "    return float(m.predict(d1).mean() - m.predict(d0).mean())\n",
    "\n",
    "def bootstrap_ci(data: pd.DataFrame, B: int = 300) -> tuple[float,float,float]:\n",
    "    vals=[]\n",
    "    n=len(data)\n",
    "    for _ in range(B):\n",
    "        samp=data.sample(n=n, replace=True)\n",
    "        vals.append(gformula_ate(samp))\n",
    "    vals=np.array(vals)\n",
    "    return float(vals.mean()), float(np.quantile(vals,0.025)), float(np.quantile(vals,0.975))\n",
    "\n",
    "bootstrap_ci(d, B=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc398fe0",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "1) What assumptions does parametric g-formula add beyond identification assumptions?\n",
    "2) How would model misspecification show up?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
