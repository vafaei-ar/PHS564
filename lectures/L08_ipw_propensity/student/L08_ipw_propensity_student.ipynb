{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "930259d7",
   "metadata": {},
   "source": [
    "# PHS564 — Lecture 08 (Student)\n",
    "## IP weighting for confounding (propensity scores) + diagnostics (MIMIC-IV Demo)\n",
    "\n",
    "### Learning goals\n",
    "- Explain IP weighting as **creating a pseudo-population** where treatment is independent of measured confounders.\n",
    "- Fit a propensity model \\(e(L)=Pr(A=1|L)\\) and compute **unstabilized** and **stabilized** weights.\n",
    "- Diagnose failure modes: **lack of overlap/positivity**, extreme weights, imbalance after weighting.\n",
    "- Produce a defensible causal estimate + a minimal diagnostics panel.\n",
    "\n",
    "### Required reading\n",
    "- Hernán & Robins, *What If*, Chapter 12 (IPW basics + intuition): https://miguelhernan.org/whatifbook\n",
    "\n",
    "**Rules for this notebook**\n",
    "- Only edit cells marked **TODO**.\n",
    "- Do not change the overall structure/cell order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90746785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab bootstrap (run this first if you opened from a Colab badge)\n",
    "# - Clones the repo into /content/PHS564 (if needed)\n",
    "# - Installs requirements\n",
    "# - Adds repo to sys.path\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def _in_colab() -> bool:\n",
    "    return \"google.colab\" in sys.modules\n",
    "\n",
    "\n",
    "if _in_colab():\n",
    "    REPO_URL = \"https://github.com/vafaei-ar/PHS564.git\"\n",
    "    TARGET_DIR = Path(\"/content/PHS564\")\n",
    "\n",
    "    if not (TARGET_DIR / \"requirements.txt\").exists():\n",
    "        print(\"Cloning course repo into Colab runtime...\")\n",
    "        subprocess.run([\"git\", \"clone\", \"--depth\", \"1\", REPO_URL, str(TARGET_DIR)], check=True)\n",
    "\n",
    "    os.chdir(TARGET_DIR)\n",
    "\n",
    "    print(\"Installing requirements...\")\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"-q\", \"install\", \"-r\", \"requirements.txt\"], check=True)\n",
    "\n",
    "    if str(TARGET_DIR) not in sys.path:\n",
    "        sys.path.insert(0, str(TARGET_DIR))\n",
    "\n",
    "    print(\"✓ Colab setup complete. Now run the rest of the notebook.\")\n",
    "else:\n",
    "    print(\"Not running in Colab; skipping Colab bootstrap.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b533b2d",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "This notebook is designed to run **locally** or in **Google Colab**.\n",
    "\n",
    "**If you opened from the Colab badge (recommended):**\n",
    "1) Run the first code cell titled **“Colab bootstrap”** (it clones the repo + installs requirements)\n",
    "2) Run the notebook top-to-bottom.\n",
    "\n",
    "**If you are running locally:**\n",
    "- Install dependencies from `requirements.txt` (see the repo `README.md`), then run top-to-bottom.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebf8799",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reproducibility\n",
    "RNG = np.random.default_rng(564)\n",
    "\n",
    "# Locate repo root (works when running from lectures/Lxx.../student or /instructor)\n",
    "THIS_DIR = Path.cwd()\n",
    "REPO_ROOT = THIS_DIR\n",
    "for _ in range(4):\n",
    "    if (REPO_ROOT / \"requirements.txt\").exists() or (REPO_ROOT / \"README.md\").exists():\n",
    "        break\n",
    "    REPO_ROOT = REPO_ROOT.parent\n",
    "\n",
    "DATA_DIR = REPO_ROOT / \"data\"\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "PROC_DIR = DATA_DIR / \"processed\"\n",
    "\n",
    "print(\"Working directory:\", THIS_DIR)\n",
    "print(\"Repo root:\", REPO_ROOT)\n",
    "print(\"Processed data dir exists:\", PROC_DIR.exists())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cda08a",
   "metadata": {},
   "source": [
    "### Build the processed cohort extract (required)\n",
    "\n",
    "This lecture expects an analysis-ready cohort file in `data/processed/`.\n",
    "\n",
    "If it’s missing, run the next cell to:\n",
    "1) download MIMIC-IV Demo into `data/raw/` (if needed)\n",
    "2) build the processed cohort extracts into `data/processed/`\n",
    "\n",
    "**Exposure mode (A):** default uses `admission_type` (contains “EMER”). You can switch to `vitals` by changing `EXPOSURE_MODE` in the code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31890804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build processed cohort extracts from raw MIMIC-IV Demo (safe to re-run)\n",
    "# This will create cohort files under data/processed/.\n",
    "\n",
    "EXPOSURE_MODE = \"admission_type\"  # or \"vitals\"\n",
    "HR_THRESHOLD = 100.0  # used only if EXPOSURE_MODE == \"vitals\"\n",
    "\n",
    "try:\n",
    "    from data.download_data import download_mimic_demo\n",
    "    from data.build_processed_extracts_demo import build_processed_extracts\n",
    "\n",
    "    mimic_dir = RAW_DIR / \"mimic-iv-demo-2.2\"\n",
    "    if not mimic_dir.exists():\n",
    "        print(\"Downloading raw MIMIC-IV Demo (v2.2) to data/raw/ ...\")\n",
    "        download_mimic_demo(out_dir=RAW_DIR, version=\"2.2\", method=\"python\")\n",
    "    else:\n",
    "        print(\"✓ Raw MIMIC-IV Demo already present.\")\n",
    "\n",
    "    out_paths = build_processed_extracts(exposure_mode=EXPOSURE_MODE, hr_threshold=HR_THRESHOLD)\n",
    "    print(\"✓ Built processed cohorts:\")\n",
    "    for k, v in out_paths.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "except Exception as e:\n",
    "    print(\"Could not build processed cohort extracts in this environment.\")\n",
    "    print(\"Error:\", e)\n",
    "    print(\"If you already have the cohort file, place it in data/processed/ and re-run.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6f72da",
   "metadata": {},
   "source": [
    "### Optional: download raw MIMIC-IV Demo tables\n",
    "\n",
    "Not required for the homework pipeline. Skip unless your instructor asks you to explore the raw Demo tables in `data/raw/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d727d72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: download raw MIMIC-IV Demo tables to data/raw/\n",
    "# Not required for the processed-cohort pipeline.\n",
    "\n",
    "try:\n",
    "    from data.download_data import download_mimic_demo\n",
    "\n",
    "    download_mimic_demo(out_dir=RAW_DIR, version=\"2.2\", method=\"python\")\n",
    "except Exception as e:\n",
    "    print(\"Skipping raw MIMIC-IV Demo download.\")\n",
    "    print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19adff8",
   "metadata": {},
   "source": [
    "## Data\n",
    "This lecture uses a **processed cohort extract** derived from MIMIC-IV Demo.\n",
    "\n",
    "Expected file:\n",
    "- `data/processed/cohort_L08_ps_ipw.parquet` (preferred) or `.csv`\n",
    "\n",
    "If this file is missing:\n",
    "- Run the “Build the processed cohort extract” cell above, or\n",
    "- Run locally: `python data/build_processed_extracts_demo.py --exposure-mode admission_type`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e1bb6b",
   "metadata": {},
   "source": [
    "### Column definitions (this cohort)\n",
    "\n",
    "These are defined by the cohort builder (`data/build_processed_extracts_demo.py`):\n",
    "\n",
    "- `A` (treatment):\n",
    "  - `EXPOSURE_MODE = \"admission_type\"` (default): `A = 1` if `admission_type` contains `\"EMER\"` (e.g., \"EW EMER.\", \"DIRECT EMER.\")\n",
    "  - `EXPOSURE_MODE = \"vitals\"` (optional): `A = 1` if mean heart rate in the **first 6 hours** of the ICU stay is `> HR_THRESHOLD`\n",
    "- `Y` (outcome): `Y = 1` if the patient **died in-hospital** (`hospital_expire_flag`)\n",
    "- `A_label`: human-readable description of the `A` definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3bcd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statsmodels for regression (logit/ols); installed via requirements.txt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Load cohort (parquet preferred, fallback to csv)\n",
    "parquet_path = PROC_DIR / \"cohort_L08_ps_ipw.parquet\"\n",
    "csv_path = PROC_DIR / \"cohort_L08_ps_ipw.csv\"\n",
    "\n",
    "if parquet_path.exists():\n",
    "    df = pd.read_parquet(parquet_path)\n",
    "elif csv_path.exists():\n",
    "    df = pd.read_csv(csv_path)\n",
    "else:\n",
    "    raise FileNotFoundError(\n",
    "        \"Cohort file not found. Expected one of:\\n\"\n",
    "        f\" - {parquet_path}\\n - {csv_path}\\n\"\n",
    "        \"Build it via:\\n\"\n",
    "        \"  - Colab: run the build cell above\\n\"\n",
    "        \"  - Local: python data/build_processed_extracts_demo.py --exposure-mode admission_type\\n\"\n",
    "    )\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fa72c9",
   "metadata": {},
   "source": [
    "### Choose variables\n",
    "We will define:\n",
    "- Treatment/exposure `A` (already in the cohort)\n",
    "- Outcome `Y` (already in the cohort)\n",
    "- Baseline covariates/confounders `L_list`\n",
    "\n",
    "For this teaching cohort, you can use `age`, `sex` and ICU length of stay `los`.\n",
    "To keep modeling simple, we will create `sex_male` as a 0/1 indicator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4102f40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables (match the built cohort)\n",
    "A = \"A\"   # treatment column\n",
    "Y = \"Y\"   # outcome (0/1): in-hospital death\n",
    "\n",
    "# Create simple numeric covariates for modeling\n",
    "if \"sex_male\" not in df.columns:\n",
    "    df[\"sex_male\"] = (df[\"sex\"].astype(str).str.upper() == \"M\").astype(int)\n",
    "\n",
    "# Baseline covariates/confounders\n",
    "L_list = [\"age\", \"sex_male\", \"los\"]\n",
    "\n",
    "# Quick sanity checks\n",
    "missing = [c for c in [A, Y, *L_list] if c not in df.columns]\n",
    "missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710a37b3",
   "metadata": {},
   "source": [
    "## Part A — Propensity score model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a268d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values in analysis variables\n",
    "analysis_vars = [A, Y] + L_list\n",
    "d = df[analysis_vars].dropna().copy()\n",
    "\n",
    "# TODO: specify the PS model. Keep it simple and explicit.\n",
    "# Example: \"A ~ age + sex + diabetes + ... \"\n",
    "ps_formula = A + \" ~ \" + \" + \".join(L_list)\n",
    "ps_model = smf.logit(ps_formula, data=d).fit(disp=False)\n",
    "\n",
    "d[\"ps\"] = ps_model.predict(d)\n",
    "\n",
    "# Stabilized weights\n",
    "pA = d[A].mean()\n",
    "d[\"sw\"] = np.where(d[A]==1, pA/d[\"ps\"], (1-pA)/(1-d[\"ps\"]))\n",
    "\n",
    "d[[\"ps\",\"sw\"]].describe(percentiles=[0.01,0.05,0.95,0.99])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f1c852",
   "metadata": {},
   "source": [
    "### TODO A1 — Weight diagnostics + truncation\n",
    "Plot the weights. Choose a truncation rule (e.g., 1st/99th percentile) and create `sw_trunc`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2b49a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(d[\"sw\"], bins=60)\n",
    "plt.xlabel(\"stabilized weight\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.title(\"Weights (before truncation)\")\n",
    "plt.show()\n",
    "\n",
    "# TODO: truncation\n",
    "lo, hi = d[\"sw\"].quantile([0.01, 0.99]).to_list()\n",
    "d[\"sw_trunc\"] = d[\"sw\"].clip(lower=lo, upper=hi)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(d[\"sw_trunc\"], bins=60)\n",
    "plt.xlabel(\"truncated weight\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.title(\"Weights (after truncation)\")\n",
    "plt.show()\n",
    "\n",
    "(lo, hi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b570d91f",
   "metadata": {},
   "source": [
    "## Part B — IPW estimate of effect\n",
    "We compute weighted mean outcomes by A. For binary Y, this estimates a risk difference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d961e573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wmean(x,w): \n",
    "    x = np.asarray(x); w = np.asarray(w)\n",
    "    return np.sum(w*x)/np.sum(w)\n",
    "\n",
    "mu1 = wmean(d.loc[d[A]==1, Y], d.loc[d[A]==1, \"sw_trunc\"])\n",
    "mu0 = wmean(d.loc[d[A]==0, Y], d.loc[d[A]==0, \"sw_trunc\"])\n",
    "ate = mu1 - mu0\n",
    "{\"mu1\": float(mu1), \"mu0\": float(mu0), \"ATE (mu1-mu0)\": float(ate)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760d7fe2",
   "metadata": {},
   "source": [
    "### TODO B1 — Sensitivity: compare to crude estimate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8235d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu1_crude = d.loc[d[A]==1, Y].mean()\n",
    "mu0_crude = d.loc[d[A]==0, Y].mean()\n",
    "ate_crude = mu1_crude - mu0_crude\n",
    "{\"crude\": float(ate_crude), \"ipw\": float(ate)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3224ad3",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "1) What does a large difference between crude and IPW imply?\n",
    "2) Which assumption is most vulnerable in EHR data: exchangeability, positivity, or consistency?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
