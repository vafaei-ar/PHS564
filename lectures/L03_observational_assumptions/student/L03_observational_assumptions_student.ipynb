{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a180d2c",
   "metadata": {},
   "source": [
    "# PHS564 — Lecture 03 (Student)\n",
    "## Causal effects in observational studies (identifiability and assumptions)\n",
    "\n",
    "### Learning goals\n",
    "- Conceptualize observational studies as “imperfect randomized experiments”.\n",
    "- State the 3 key identifiability conditions: exchangeability, positivity, well-defined interventions.\n",
    "- Recognize why conditional exchangeability cannot be tested from observed data alone.\n",
    "\n",
    "### Required reading\n",
    "- Hernán & Robins, Chapter 3. https://miguelhernan.org/whatifbook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888883ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab bootstrap (run this first if you opened from a Colab badge)\n",
    "# - Clones the repo into /content/PHS564 (if needed)\n",
    "# - Installs requirements\n",
    "# - Adds repo to sys.path\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def _in_colab() -> bool:\n",
    "    return \"google.colab\" in sys.modules\n",
    "\n",
    "\n",
    "if _in_colab():\n",
    "    REPO_URL = \"https://github.com/vafaei-ar/PHS564.git\"\n",
    "    TARGET_DIR = Path(\"/content/PHS564\")\n",
    "\n",
    "    if not (TARGET_DIR / \"requirements.txt\").exists():\n",
    "        print(\"Cloning course repo into Colab runtime...\")\n",
    "        subprocess.run([\"git\", \"clone\", \"--depth\", \"1\", REPO_URL, str(TARGET_DIR)], check=True)\n",
    "\n",
    "    os.chdir(TARGET_DIR)\n",
    "\n",
    "    print(\"Installing requirements...\")\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"-q\", \"install\", \"-r\", \"requirements.txt\"], check=True)\n",
    "\n",
    "    if str(TARGET_DIR) not in sys.path:\n",
    "        sys.path.insert(0, str(TARGET_DIR))\n",
    "\n",
    "    print(\"✓ Colab setup complete. Now run the rest of the notebook.\")\n",
    "else:\n",
    "    print(\"Not running in Colab; skipping Colab bootstrap.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0408abd7",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "This notebook is designed to run **locally** or in **Google Colab**.\n",
    "\n",
    "**Colab workflow (recommended):**\n",
    "1) Clone the course repo (ask the instructor for the GitHub URL).\n",
    "2) Install requirements.\n",
    "3) Run the notebook top-to-bottom.\n",
    "\n",
    "> If you opened this notebook directly from GitHub in Colab (without cloning),\n",
    "> relative paths will not work. Clone first.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014299ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reproducibility\n",
    "RNG = np.random.default_rng(564)\n",
    "\n",
    "# Locate repo root (works when running from lectures/Lxx.../student or /instructor)\n",
    "THIS_DIR = Path.cwd()\n",
    "REPO_ROOT = THIS_DIR\n",
    "for _ in range(4):\n",
    "    if (REPO_ROOT / \"requirements.txt\").exists() or (REPO_ROOT / \"README.md\").exists():\n",
    "        break\n",
    "    REPO_ROOT = REPO_ROOT.parent\n",
    "\n",
    "DATA_DIR = REPO_ROOT / \"data\"\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "PROC_DIR = DATA_DIR / \"processed\"\n",
    "\n",
    "print(\"Working directory:\", THIS_DIR)\n",
    "print(\"Repo root:\", REPO_ROOT)\n",
    "print(\"Processed data dir exists:\", PROC_DIR.exists())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd6a73a",
   "metadata": {},
   "source": [
    "## Part A — Observational study as a conditionally randomized experiment\n",
    "We simulate confounding via a measured covariate `L`. The goal is to estimate the ATE of `A` on `Y`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a806d332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statsmodels for regression (logit/ols); installed via requirements.txt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "n = 3000\n",
    "L = RNG.normal(size=n)\n",
    "# treatment depends on L (confounding)\n",
    "pA = 1/(1+np.exp(-(-0.2 + 1.2*L)))\n",
    "A = RNG.binomial(1, pA)\n",
    "# outcome depends on A and L\n",
    "pY = 1/(1+np.exp(-(-1.0 + 0.8*A + 1.0*L)))\n",
    "Y = RNG.binomial(1, pY)\n",
    "df = pd.DataFrame({\"L\":L, \"A\":A, \"Y\":Y})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3adda67",
   "metadata": {},
   "source": [
    "### TODO A1 — Naïve (confounded) estimate\n",
    "Compute the crude RD: E[Y|A=1]-E[Y|A=0].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf76de39",
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_crude = None  # TODO\n",
    "rd_crude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c00517e",
   "metadata": {},
   "source": [
    "## Part B — Standardization (g-formula) with a correctly specified model\n",
    "We fit an outcome model E[Y|A,L] and standardize over the empirical distribution of L.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26e1c25",
   "metadata": {},
   "source": [
    "### TODO B1 — Fit a logistic outcome regression\n",
    "Fill in the formula and fit the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d82518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: choose a reasonable model for Pr(Y=1 | A, L)\n",
    "formula = \"Y ~ A + L\"  # you may extend (e.g., L^2)\n",
    "model_y = smf.logit(formula=formula, data=df).fit(disp=False)\n",
    "model_y.summary().tables[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0cd3e0",
   "metadata": {},
   "source": [
    "### TODO B2 — Standardize: predict under A=1 and A=0 and average\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fce6431",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy(); df1[\"A\"] = 1\n",
    "df0 = df.copy(); df0[\"A\"] = 0\n",
    "\n",
    "# TODO: use model_y.predict to get predicted risk under A=1 and A=0\n",
    "mu1 = None\n",
    "mu0 = None\n",
    "rd_std = None\n",
    "\n",
    "{\"mu1\": mu1, \"mu0\": mu0, \"rd_std\": rd_std}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11027b1",
   "metadata": {},
   "source": [
    "## Part C — IP weighting (propensity score)\n",
    "We fit a treatment model Pr(A=1|L), compute stabilized weights, and estimate RD in the pseudo-population.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d8060c",
   "metadata": {},
   "source": [
    "### TODO C1 — Fit propensity score model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015c4fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: propensity model for A given L\n",
    "ps_model = smf.logit(formula=\"A ~ L\", data=df).fit(disp=False)\n",
    "df[\"ps\"] = ps_model.predict(df)\n",
    "\n",
    "# Stabilized weights: numerator Pr(A) and denominator Pr(A|L)\n",
    "pA_marg = df[\"A\"].mean()\n",
    "df[\"sw\"] = np.where(df[\"A\"]==1, pA_marg/df[\"ps\"], (1-pA_marg)/(1-df[\"ps\"]))\n",
    "df[[\"ps\",\"sw\"]].describe(percentiles=[0.01,0.05,0.95,0.99])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c22c14",
   "metadata": {},
   "source": [
    "### TODO C2 — Weighted RD\n",
    "Compute weighted means of Y by A, then RD.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f83b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wmean(x, w):\n",
    "    return np.sum(w*x)/np.sum(w)\n",
    "\n",
    "mu1_w = wmean(df.loc[df[\"A\"]==1,\"Y\"].to_numpy(), df.loc[df[\"A\"]==1,\"sw\"].to_numpy())\n",
    "mu0_w = wmean(df.loc[df[\"A\"]==0,\"Y\"].to_numpy(), df.loc[df[\"A\"]==0,\"sw\"].to_numpy())\n",
    "rd_ipw = mu1_w - mu0_w\n",
    "{\"mu1_w\": mu1_w, \"mu0_w\": mu0_w, \"rd_ipw\": rd_ipw}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2f16b0",
   "metadata": {},
   "source": [
    "### Diagnostics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7318f06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(df[\"sw\"], bins=60)\n",
    "plt.xlabel(\"stabilized weight\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.title(\"Weight distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69aded7",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "1) Which assumptions are required for standardization and IPW to identify the ATE?\n",
    "2) What is positivity, and how would it show up in the weights?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
