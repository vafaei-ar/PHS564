{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e14ab23",
   "metadata": {},
   "source": [
    "# PHS564 — Lecture 10 (Student)\n",
    "## Causal survival analysis: time-to-event outcomes, censoring, discrete-time hazards (MIMIC-IV Demo)\n",
    "\n",
    "### Learning goals\n",
    "- Distinguish **risk** vs **hazard** vs **survival**; know what effect measure you are estimating.\n",
    "- Convert a cohort into **person-period** (discrete time) data and fit pooled logistic hazards.\n",
    "- Handle **right censoring** with **IPCW**; understand when censoring is “informative”.\n",
    "- Produce causal survival curves under a point treatment (and interpret assumptions).\n",
    "\n",
    "### Required reading\n",
    "- Hernán & Robins, sections on censoring and survival (target trial chapters/sections as applicable).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb39136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab bootstrap (run this first if you opened from a Colab badge)\n",
    "# - Clones the repo into /content/PHS564 (if needed)\n",
    "# - Installs requirements\n",
    "# - Adds repo to sys.path\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def _in_colab() -> bool:\n",
    "    return \"google.colab\" in sys.modules\n",
    "\n",
    "\n",
    "if _in_colab():\n",
    "    REPO_URL = \"https://github.com/vafaei-ar/PHS564.git\"\n",
    "    TARGET_DIR = Path(\"/content/PHS564\")\n",
    "\n",
    "    if not (TARGET_DIR / \"requirements.txt\").exists():\n",
    "        print(\"Cloning course repo into Colab runtime...\")\n",
    "        subprocess.run([\"git\", \"clone\", \"--depth\", \"1\", REPO_URL, str(TARGET_DIR)], check=True)\n",
    "\n",
    "    os.chdir(TARGET_DIR)\n",
    "\n",
    "    print(\"Installing requirements...\")\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"-q\", \"install\", \"-r\", \"requirements.txt\"], check=True)\n",
    "\n",
    "    if str(TARGET_DIR) not in sys.path:\n",
    "        sys.path.insert(0, str(TARGET_DIR))\n",
    "\n",
    "    print(\"✓ Colab setup complete. Now run the rest of the notebook.\")\n",
    "else:\n",
    "    print(\"Not running in Colab; skipping Colab bootstrap.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642b5d96",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "This notebook is designed to run **locally** or in **Google Colab**.\n",
    "\n",
    "**Colab workflow (recommended):**\n",
    "1) Clone the course repo (ask the instructor for the GitHub URL).\n",
    "2) Install requirements.\n",
    "3) Run the notebook top-to-bottom.\n",
    "\n",
    "> If you opened this notebook directly from GitHub in Colab (without cloning),\n",
    "> relative paths will not work. Clone first.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6291d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reproducibility\n",
    "RNG = np.random.default_rng(564)\n",
    "\n",
    "# Locate repo root (works when running from lectures/Lxx.../student or /instructor)\n",
    "THIS_DIR = Path.cwd()\n",
    "REPO_ROOT = THIS_DIR\n",
    "for _ in range(4):\n",
    "    if (REPO_ROOT / \"requirements.txt\").exists() or (REPO_ROOT / \"README.md\").exists():\n",
    "        break\n",
    "    REPO_ROOT = REPO_ROOT.parent\n",
    "\n",
    "DATA_DIR = REPO_ROOT / \"data\"\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "PROC_DIR = DATA_DIR / \"processed\"\n",
    "\n",
    "print(\"Working directory:\", THIS_DIR)\n",
    "print(\"Repo root:\", REPO_ROOT)\n",
    "print(\"Processed data dir exists:\", PROC_DIR.exists())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8bb4ef",
   "metadata": {},
   "source": [
    "### Download the processed cohort extract (required)\n",
    "\n",
    "This lecture uses a **processed cohort extract** hosted as a **GitHub Release asset**.\n",
    "\n",
    "- If you are running in **Google Colab**, run the next cell once to download the processed cohort into `data/processed/`.\n",
    "- Downloading raw MIMIC-IV Demo tables is optional and **not required** for this lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e846c52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download processed cohort extract for L10 (safe to re-run)\n",
    "# Downloads into data/processed/ from GitHub Releases.\n",
    "\n",
    "try:\n",
    "    from data.download_data import download_course_extracts\n",
    "\n",
    "    download_course_extracts(\"L10\", out_dir=PROC_DIR)\n",
    "except Exception as e:\n",
    "    print(\"Could not download the processed cohort extract for L10.\")\n",
    "    print(\"Error:\", e)\n",
    "    print(\"If you already have the cohort file, place it in data/processed/ and re-run.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3fc5dc",
   "metadata": {},
   "source": [
    "### Optional: download raw MIMIC-IV Demo tables\n",
    "\n",
    "Not required for the homework pipeline. Skip unless your instructor asks you to explore the raw Demo tables in `data/raw/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3991e79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: download raw MIMIC-IV Demo tables to data/raw/\n",
    "# Not required for the processed-cohort pipeline.\n",
    "\n",
    "try:\n",
    "    from data.download_data import download_mimic_demo\n",
    "\n",
    "    download_mimic_demo(out_dir=RAW_DIR, version=\"2.2\", method=\"python\")\n",
    "except Exception as e:\n",
    "    print(\"Skipping raw MIMIC-IV Demo download.\")\n",
    "    print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21310d6f",
   "metadata": {},
   "source": [
    "## Data\n",
    "This lecture uses a **processed cohort extract** derived from MIMIC-IV Demo.\n",
    "\n",
    "Expected file: `data/processed/cohort_L10_survival.parquet` (or `.csv`).\n",
    "\n",
    "If this file is missing:\n",
    "- In Colab: run the “Download the processed cohort extract” cell above.\n",
    "- Or locally: run `python data/download_data.py --lecture L10` (downloads into `data/processed/`).\n",
    "\n",
    "Assumed columns (you may adapt to the actual extract):\n",
    "- `A` treatment at baseline\n",
    "- `T` follow-up time (in discrete intervals)\n",
    "- `E` event indicator (1=event, 0=censored)\n",
    "- baseline covariates (e.g., age, sex, severity)\n",
    "\n",
    "We will fit a **discrete-time hazard** model via logistic regression on a person-period dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1533e646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statsmodels for regression (logit/ols); installed via requirements.txt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "parquet_path = PROC_DIR / \"cohort_L10_survival.parquet\"\n",
    "csv_path = PROC_DIR / \"cohort_L10_survival.csv\"\n",
    "\n",
    "if parquet_path.exists():\n",
    "    df = pd.read_parquet(parquet_path)\n",
    "elif csv_path.exists():\n",
    "    df = pd.read_csv(csv_path)\n",
    "else:\n",
    "    raise FileNotFoundError(\n",
    "        \"Missing cohort file for L10. Download it via:\\n\"\n",
    "        \"  - Colab: run the download cell above\\n\"\n",
    "        \"  - Local: python data/download_data.py --lecture L10\\n\"\n",
    "    )\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0409da",
   "metadata": {},
   "source": [
    "### TODO A1 — Create person-period dataset\n",
    "If your extract is already long-format (one row per person-period), skip this.\n",
    "Otherwise, expand each subject into rows `t=1..T` and set event indicator at the event time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e59fcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected: either already long with columns ['id','t','A','E_t', ...]\n",
    "# or wide with ['id','T','E', ...]\n",
    "# TODO: adapt based on df columns.\n",
    "\n",
    "long = df.copy()  # placeholder\n",
    "long.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f46dbe",
   "metadata": {},
   "source": [
    "## Part B — Discrete-time hazard model\n",
    "We model Pr(E_t=1 | E_{t-1}=0, A, L, t).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a845d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: set outcome and covariates\n",
    "# Recommended structure:\n",
    "#   hazard_formula = \"E_t ~ A + age + sex + C(t)\"  (with t as categorical or spline)\n",
    "hazard_formula = \"E_t ~ A + t\"  # TODO\n",
    "# Fit model\n",
    "haz_model = smf.logit(hazard_formula, data=long).fit(disp=False)\n",
    "haz_model.params.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b043fa",
   "metadata": {},
   "source": [
    "### TODO B1 — Predict survival curves under A=1 and A=0 (g-formula)\n",
    "Compute survival S(t) = Π_{k<=t} (1 - h(k)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8228704",
   "metadata": {},
   "outputs": [],
   "source": [
    "def survival_curve(data_long: pd.DataFrame, A_value: int, t_col: str = \"t\") -> pd.DataFrame:\n",
    "    # data_long contains one row per person-period and baseline covariates.\n",
    "    d = data_long.copy()\n",
    "    d[\"A\"] = A_value\n",
    "    d[\"haz\"] = haz_model.predict(d)\n",
    "    # average hazard per time\n",
    "    hz = d.groupby(t_col)[\"haz\"].mean().sort_index()\n",
    "    surv = (1 - hz).cumprod()\n",
    "    return pd.DataFrame({\"t\": hz.index, \"haz\": hz.values, \"surv\": surv.values})\n",
    "\n",
    "# TODO: adapt t column name if needed\n",
    "curve1 = survival_curve(long, 1)\n",
    "curve0 = survival_curve(long, 0)\n",
    "curve1.head(), curve0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8276cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.step(curve0[\"t\"], curve0[\"surv\"], where=\"post\", label=\"A=0\")\n",
    "plt.step(curve1[\"t\"], curve1[\"surv\"], where=\"post\", label=\"A=1\")\n",
    "plt.xlabel(\"time interval\")\n",
    "plt.ylabel(\"Survival S(t)\")\n",
    "plt.legend()\n",
    "plt.title(\"Estimated survival curves (discrete-time)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96435d7d",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "1) Why is time-to-event analysis central to target trial emulation?\n",
    "2) What is the difference between hazard and risk, and why does it matter?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
